---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: Modelfile
data:
  Modelfile: |-
     FROM granite3.3
     PARAMETER temperature 1
     PARAMETER num_ctx 4096

     SYSTEM You are an assistant to a team of SREs working for an open-source software company.

---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    io.podman.annotations.userns/ollama: keep-id
  labels:
    app: ollama
  name: ollama
spec:
  containers:
  - command:
    - /bin/ollama
    - serve
    env:
      - name: OLLAMA_HOST
        value: 0.0.0.0:11434
      - name: HOME
        value: /home/ollama
    image: quay.io/chcollin/toolbox-ollama:1a1b246
    name: serve
    resources:
      requests:
        cpu: 4096m
        memory: 8Gi
      limits:
        cpu: 8192m
        memory: 12Gi
    securityContext:
      runAsNonRoot: true
      privileged: false
      seLinuxOptions:
        type: spc_t
    volumeMounts:
    - mountPath: "/home/ollama"
      name: Modelfile
    - mountPath: "/home/ollama/.ollama"
      name: ollama
  - command:
    - "/bin/bash"
    - "-c"
    - "trap TERM INT; sleep infinity & wait"
    env:
      - name: OLLAMA_HOST
        value: 0.0.0.0:11434
    image: quay.io/chcollin/toolbox-ollama:1a1b246
    name: cli
    resources:
      requests:
        cpu: 1024m
        memory: 512Mi
    securityContext:
      runAsNonRoot: true
      privileged: false
      seLinuxOptions:
        type: spc_t
    volumeMounts:
    - mountPath: "/home/ollama"
      name: Modelfile
  volumes:
  - name: Modelfile
    configMap:
      name: Modelfile
  - name: ollama
    persistentVolumeClaim:
      claimName: ollama
  restartPolicy: Always
